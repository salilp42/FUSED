{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUSED Framework: Hyperparameter Optimization Example\n",
    "\n",
    "This notebook demonstrates how to use the hyperparameter optimization utilities in the FUSED framework to automatically find the best configuration for your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and setup our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Import FUSED utilities\n",
    "from fused.utils.hyperparameter_optimization import HyperparameterTuner, OptunaOptimizer\n",
    "from fused.models import SequentialEncoder, TemporalFusionModel\n",
    "from fused.utils.experiment_tracking import ExperimentTracker\n",
    "\n",
    "# Enable interactive plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Data\n",
    "\n",
    "Let's create some synthetic multimodal time series data for our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples=1000, seq_length=50, n_features=10, n_modalities=2):\n",
    "    \"\"\"Generate synthetic multimodal time series data.\"\"\"\n",
    "    # Create modalities\n",
    "    modalities = {}\n",
    "    \n",
    "    for i in range(n_modalities):\n",
    "        # Generate random time series\n",
    "        X = torch.randn(n_samples, seq_length, n_features)\n",
    "        \n",
    "        # Add some patterns\n",
    "        freq = 0.1 * (i + 1)\n",
    "        t = torch.linspace(0, 1, seq_length).unsqueeze(0).unsqueeze(-1)\n",
    "        sin_pattern = torch.sin(2 * np.pi * freq * t) * 2.0\n",
    "        cos_pattern = torch.cos(2 * np.pi * freq * t) * 2.0\n",
    "        \n",
    "        # Add patterns to first few features\n",
    "        X[:, :, 0:1] += sin_pattern\n",
    "        X[:, :, 1:2] += cos_pattern\n",
    "        \n",
    "        modalities[f\"modality_{i}\"] = X\n",
    "    \n",
    "    # Generate labels based on the patterns\n",
    "    y = torch.zeros(n_samples)\n",
    "    sin_sum = torch.sum(modalities[\"modality_0\"][:, :, 0], dim=1)\n",
    "    cos_sum = torch.sum(modalities[\"modality_1\"][:, :, 1], dim=1) if n_modalities > 1 else 0\n",
    "    \n",
    "    # Class is determined by the sum of sin and cos patterns\n",
    "    y = (sin_sum + cos_sum > 0).float()\n",
    "    \n",
    "    return modalities, y\n",
    "\n",
    "# Generate data\n",
    "modalities, labels = generate_synthetic_data()\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_size = int(0.8 * len(labels))\n",
    "train_indices = torch.randperm(len(labels))[:train_size]\n",
    "val_indices = torch.randperm(len(labels))[train_size:]\n",
    "\n",
    "train_modalities = {k: v[train_indices] for k, v in modalities.items()}\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "val_modalities = {k: v[val_indices] for k, v in modalities.items()}\n",
    "val_labels = labels[val_indices]\n",
    "\n",
    "# Create datasets\n",
    "def create_dataset(modalities, labels):\n",
    "    # For simplicity, we'll combine all modalities and labels in a dictionary\n",
    "    data_dict = {**modalities, \"labels\": labels}\n",
    "    return data_dict\n",
    "\n",
    "train_dataset = create_dataset(train_modalities, train_labels)\n",
    "val_dataset = create_dataset(val_modalities, val_labels)\n",
    "\n",
    "print(f\"Train dataset: {len(train_labels)} samples\")\n",
    "print(f\"Validation dataset: {len(val_labels)} samples\")\n",
    "\n",
    "# Let's visualize a sample\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(modalities[\"modality_0\"][0, :, 0].numpy())\n",
    "plt.title(f\"Modality 0, Feature 0 (Label: {labels[0].item()})\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(modalities[\"modality_1\"][0, :, 1].numpy())\n",
    "plt.title(f\"Modality 1, Feature 1 (Label: {labels[0].item()})\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a FUSED Model\n",
    "\n",
    "Now, let's define a simple FUSED model with configurable hyperparameters that we'll optimize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalClassifier(nn.Module):\n",
    "    \"\"\"A simple multimodal classifier using FUSED components.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Extract configuration parameters\n",
    "        hidden_dim = config.get(\"hidden_dim\", 64)\n",
    "        num_layers = config.get(\"num_layers\", 2)\n",
    "        dropout_rate = config.get(\"dropout_rate\", 0.1)\n",
    "        bidirectional = config.get(\"bidirectional\", True)\n",
    "        fusion_type = config.get(\"fusion_type\", \"attention\")\n",
    "        \n",
    "        # Create encoders for each modality\n",
    "        self.encoders = nn.ModuleDict()\n",
    "        for modality in [\"modality_0\", \"modality_1\"]:\n",
    "            self.encoders[modality] = SequentialEncoder(\n",
    "                input_dim=10,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=hidden_dim,\n",
    "                num_layers=num_layers,\n",
    "                bidirectional=bidirectional,\n",
    "                dropout=dropout_rate,\n",
    "                encoder_type=\"lstm\"\n",
    "            )\n",
    "        \n",
    "        # Create fusion model\n",
    "        self.fusion = TemporalFusionModel(\n",
    "            input_dim=hidden_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=hidden_dim,\n",
    "            num_modalities=2,\n",
    "            fusion_type=fusion_type,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.classifier = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Encode each modality\n",
    "        encoded = {}\n",
    "        for modality, encoder in self.encoders.items():\n",
    "            encoded[modality] = encoder(inputs[modality])\n",
    "        \n",
    "        # Fuse representations\n",
    "        fused = self.fusion(encoded)\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(fused)\n",
    "        \n",
    "        return {\"logits\": logits.squeeze(-1)}\n",
    "    \n",
    "    def fit(self, train_data, validation_data=None, epochs=10, lr=0.001, batch_size=32):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            epoch_loss = 0.0\n",
    "            \n",
    "            # Process data in batches\n",
    "            for i in range(0, len(train_data[\"labels\"]), batch_size):\n",
    "                batch_end = min(i + batch_size, len(train_data[\"labels\"]))\n",
    "                \n",
    "                # Prepare batch\n",
    "                batch = {}\n",
    "                for k, v in train_data.items():\n",
    "                    if k == \"labels\":\n",
    "                        batch[k] = v[i:batch_end].to(device)\n",
    "                    else:\n",
    "                        batch[k] = v[i:batch_end].to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(batch)\n",
    "                loss = criterion(outputs[\"logits\"], batch[\"labels\"])\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item() * (batch_end - i)\n",
    "            \n",
    "            epoch_loss /= len(train_data[\"labels\"])\n",
    "            \n",
    "            # Validation\n",
    "            if validation_data is not None:\n",
    "                self.eval()\n",
    "                val_loss = 0.0\n",
    "                val_correct = 0\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for i in range(0, len(validation_data[\"labels\"]), batch_size):\n",
    "                        batch_end = min(i + batch_size, len(validation_data[\"labels\"]))\n",
    "                        \n",
    "                        # Prepare batch\n",
    "                        batch = {}\n",
    "                        for k, v in validation_data.items():\n",
    "                            if k == \"labels\":\n",
    "                                batch[k] = v[i:batch_end].to(device)\n",
    "                            else:\n",
    "                                batch[k] = v[i:batch_end].to(device)\n",
    "                        \n",
    "                        # Forward pass\n",
    "                        outputs = self(batch)\n",
    "                        loss = criterion(outputs[\"logits\"], batch[\"labels\"])\n",
    "                        \n",
    "                        val_loss += loss.item() * (batch_end - i)\n",
    "                        \n",
    "                        # Calculate accuracy\n",
    "                        preds = (outputs[\"logits\"] > 0).float()\n",
    "                        val_correct += (preds == batch[\"labels\"]).sum().item()\n",
    "                \n",
    "                val_loss /= len(validation_data[\"labels\"])\n",
    "                val_acc = val_correct / len(validation_data[\"labels\"])\n",
    "                \n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "                return {\"val_loss\": val_loss, \"val_acc\": val_acc}\n",
    "            else:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")\n",
    "                return {\"loss\": epoch_loss}\n",
    "\n",
    "# Test the model\n",
    "test_config = {\n",
    "    \"hidden_dim\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"bidirectional\": True,\n",
    "    \"fusion_type\": \"attention\"\n",
    "}\n",
    "\n",
    "model = MultimodalClassifier(test_config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Search Space\n",
    "\n",
    "Now, let's define the hyperparameter search space for our optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"hidden_dim\": {\n",
    "        \"type\": \"int\",\n",
    "        \"low\": 32,\n",
    "        \"high\": 128,\n",
    "        \"step\": 16\n",
    "    },\n",
    "    \"num_layers\": {\n",
    "        \"type\": \"int\",\n",
    "        \"low\": 1,\n",
    "        \"high\": 3\n",
    "    },\n",
    "    \"dropout_rate\": {\n",
    "        \"type\": \"float\",\n",
    "        \"low\": 0.0,\n",
    "        \"high\": 0.5\n",
    "    },\n",
    "    \"bidirectional\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"choices\": [True, False]\n",
    "    },\n",
    "    \"fusion_type\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"choices\": [\"attention\", \"concat\", \"mean\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Hyperparameter Optimization\n",
    "\n",
    "Now, let's use the `HyperparameterTuner` to find the optimal configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the optimizer\n",
    "optimizer_config = {\n",
    "    \"direction\": \"minimize\",   # Minimize validation loss\n",
    "    \"n_trials\": 20,            # Number of trials to run\n",
    "    \"study_name\": \"multimodal_classifier\",\n",
    "    \"storage\": \"sqlite:///study.db\"  # Save results to a database\n",
    "}\n",
    "\n",
    "# Create tuner\n",
    "tuner = HyperparameterTuner(\n",
    "    optimizer_type=\"optuna\",\n",
    "    optimizer_config=optimizer_config,\n",
    "    cv_folds=3,  # Use 3-fold cross-validation\n",
    ")\n",
    "\n",
    "# Optional: Create an experiment tracker\n",
    "tracker = ExperimentTracker(\n",
    "    experiment_name=\"hyperparameter_optimization\",\n",
    "    tracking_uri=\".\",  # Local tracking\n",
    "    experiment_tags={\"task\": \"classification\", \"data\": \"synthetic\"}\n",
    ")\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "best_params, best_model = tuner.tune(\n",
    "    model_class=MultimodalClassifier,\n",
    "    dataset=train_dataset,\n",
    "    validation_dataset=val_dataset,\n",
    "    search_space=search_space,\n",
    "    eval_metric=\"val_loss\",\n",
    "    direction=\"minimize\",\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    lr=0.001,\n",
    "    experiment_tracker=tracker,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Let's analyze the optimization results and look at the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# If we used Optuna, we can visualize the optimization history\n",
    "if isinstance(tuner.optimizer, OptunaOptimizer) and tuner.optimizer.study is not None:\n",
    "    # Import optuna visualization\n",
    "    import optuna.visualization as vis\n",
    "    \n",
    "    # Plot optimization history\n",
    "    fig = vis.plot_optimization_history(tuner.optimizer.study)\n",
    "    fig.show()\n",
    "    \n",
    "    # Plot parameter importances\n",
    "    fig = vis.plot_param_importances(tuner.optimizer.study)\n",
    "    fig.show()\n",
    "    \n",
    "    # Plot slice of parameter space\n",
    "    fig = vis.plot_slice(tuner.optimizer.study)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Best Model\n",
    "\n",
    "Now, let's evaluate the performance of the best model on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to CPU for evaluation\n",
    "best_model = best_model.cpu()\n",
    "best_model.eval()\n",
    "\n",
    "# Prepare validation data\n",
    "batch_size = 32\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(val_dataset[\"labels\"]), batch_size):\n",
    "        batch_end = min(i + batch_size, len(val_dataset[\"labels\"]))\n",
    "        \n",
    "        # Prepare batch\n",
    "        batch = {}\n",
    "        for k, v in val_dataset.items():\n",
    "            if k == \"labels\":\n",
    "                batch[k] = v[i:batch_end]\n",
    "            else:\n",
    "                batch[k] = v[i:batch_end]\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = best_model(batch)\n",
    "        preds = (outputs[\"logits\"] > 0).float()\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(batch[\"labels\"])\n",
    "\n",
    "# Concatenate results\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (all_preds == all_labels).float().mean().item()\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(all_labels, all_preds)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Best Model\n",
    "\n",
    "Finally, let's save the best model configuration and weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model configuration and weights\n",
    "from fused.utils.serving import ModelExporter\n",
    "\n",
    "# Create exporter\n",
    "exporter = ModelExporter(best_model, save_dir=\"./saved_models\")\n",
    "\n",
    "# Export model\n",
    "torch_path = exporter.export_pytorch(filename=\"best_multimodal_model.pt\")\n",
    "config_path = exporter.export_config(filename=\"best_multimodal_config.json\")\n",
    "\n",
    "print(f\"Model saved to {torch_path}\")\n",
    "print(f\"Config saved to {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the hyperparameter optimization utilities in the FUSED framework to automatically find the best configuration for a multimodal time series model. We've covered:\n",
    "\n",
    "1. Creating a synthetic multimodal dataset\n",
    "2. Defining a model using FUSED components\n",
    "3. Specifying a hyperparameter search space\n",
    "4. Running the optimization process\n",
    "5. Analyzing and visualizing the results\n",
    "6. Evaluating and saving the best model\n",
    "\n",
    "The `HyperparameterTuner` class makes it easy to integrate with different optimization backends like Optuna and Ray Tune, enabling efficient hyperparameter search for complex models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
